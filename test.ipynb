{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mglearn in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from mglearn) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from mglearn) (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from mglearn) (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from mglearn) (2.2.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from mglearn) (10.4.0)\n",
      "Requirement already satisfied: cycler in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from mglearn) (0.11.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from mglearn) (2.33.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from mglearn) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from matplotlib->mglearn) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from matplotlib->mglearn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from matplotlib->mglearn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from matplotlib->mglearn) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from matplotlib->mglearn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from matplotlib->mglearn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from pandas->mglearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from pandas->mglearn) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from scikit-learn->mglearn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from scikit-learn->mglearn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\a81u\\ml\\introduction_to_ml_with_python\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import matplotlib_inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "from cycler import cycler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Libreria per importare CSV da Drive\n",
    "# from google.colab import drive\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'png')\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['image.cmap'] = \"viridis\"\n",
    "plt.rcParams['image.interpolation'] = \"none\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['legend.numpoints'] = 1\n",
    "plt.rc('axes', prop_cycle=(\n",
    "    cycler('color', mglearn.plot_helpers.cm_cycle.colors) +\n",
    "    cycler('linestyle', ['-', '-', \"--\", (0, (3, 3)), (0, (1.5, 1.5))])))\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 16)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "__all__ = ['np', 'mglearn', 'display', 'plt', 'pd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelli = ['LogisticRegression', 'KNeighborsClassifier',' DecisionTreeClassifier', 'RandomForestClassifier' ,'SVC', 'GaussianNB', 'LinearDiscriminantAnalysis', 'AdaBoostClassifier' ]\n",
    "modelli = ['RandomForestClassifier']\n",
    "def mod(modello):\n",
    "    if modello == 'LogisticRegression':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        model = LogisticRegression()\n",
    "    \n",
    "    if modello == 'KNeighborsClassifier':\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    if modello == 'DecisionTreeClassifier':\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        model = DecisionTreeClassifier()\n",
    "    if modello == 'RandomForestClassifier':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier()\n",
    "    if modello == 'SVC':\n",
    "        from sklearn.svm import SVC\n",
    "        model = SVC(kernel='linear')\n",
    "    if modello == 'GaussianNB':\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        model = GaussianNB()\n",
    "    if modello == 'LinearDiscriminantAnalysis':\n",
    "        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "        model = LinearDiscriminantAnalysis()\n",
    "    if modello == 'AdaBoostClassifier':\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        model = AdaBoostClassifier()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def ohe(df, list_of_columns):\n",
    "    # Inizializzare OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    \n",
    "    # Manteniamo una copia del DataFrame originale\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # Iterare sulle colonne da codificare\n",
    "    for col in list_of_columns:\n",
    "        # Applicare OneHotEncoder alla colonna specifica\n",
    "        encoded = encoder.fit_transform(df[[col]])\n",
    "\n",
    "        # Creare un DataFrame con le nuove colonne codificate, usando gli stessi indici del DataFrame originale\n",
    "        encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([col]), index=df.index)\n",
    "\n",
    "        # Concatenare le nuove colonne codificate al DataFrame originale\n",
    "        df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "    df_encoded = df_encoded.drop(list_of_columns, axis=1)\n",
    "\n",
    "    # Restituire il DataFrame finale, mantenendo le colonne originali\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base.csv\n",
      "Variant I.csv\n",
      "Variant II.csv\n",
      "Variant III.csv\n",
      "Variant IV.csv\n",
      "Variant V.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith('.csv'):\n",
    "        print(filename)\n",
    "        df_ = pd.read_csv(filename).drop(['device_fraud_count', 'month'], axis=1)\n",
    "        if 'x1' in list(df_.columns):\n",
    "            df_ = df_.drop(['x1', 'x2'], axis=1)\n",
    "        df_['fonte'] = filename\n",
    "        dfs.append(df_)\n",
    "df = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_fonti = ['Base.csv', 'Variant I.csv', 'Variant II.csv','Variant III.csv','Variant IV.csv','Variant V.csv']\n",
    "diz_df = dict()\n",
    "for l in lista_fonti:\n",
    "    diz_df[l] = df[(df['fonte'] == l)].drop(['fonte'], axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Base.csv', 'Variant I.csv', 'Variant II.csv', 'Variant III.csv', 'Variant IV.csv', 'Variant V.csv'])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diz_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11029\n"
     ]
    }
   ],
   "source": [
    "df = diz_df['Base.csv']\n",
    "df_frodi = df[(df['fraud_bool'] == 1)]\n",
    "n = df[(df['fraud_bool'] == 1)].shape[0]\n",
    "print(n)\n",
    "df_not_frodi = df[(df['fraud_bool'] != 1)]#.head(n*50)\n",
    "\n",
    "df = pd.concat([df_frodi, df_not_frodi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier()\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df = ohe(df,['employment_status','payment_type','housing_status', 'source', 'device_os'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(['fraud_bool'], axis=1), df['fraud_bool'], random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuratezza: {accuracy}')\n",
    "\n",
    "    # Calcolare la precisione\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f'Precisione: {precision}')\n",
    "\n",
    "    # Calcolare il recall (sensibilità)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Matrice di confusione:\\n{cm}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(df, model):\n",
    "    \n",
    "    df = ohe(df,['employment_status','payment_type','housing_status', 'source', 'device_os'])\n",
    "    y_pred = model.predict(df.drop(['fraud_bool'], axis=1))\n",
    "    y_test = df['fraud_bool']\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuratezza: {accuracy}')\n",
    "\n",
    "    # Calcolare la precisione\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f'Precisione: {precision}')\n",
    "\n",
    "    # Calcolare il recall (sensibilità)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Matrice di confusione:\\n{cm}')\n",
    "\n",
    "    print('\\n__________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.988976\n",
      "Precisione: 0.8333333333333334\n",
      "Recall: 0.0018115942028985507\n",
      "Matrice di confusione:\n",
      "[[247239      1]\n",
      " [  2755      5]]\n"
     ]
    }
   ],
   "source": [
    "model = train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Base.csv\n",
      "Accuratezza: 0.997227\n",
      "Precisione: 0.9998789053039477\n",
      "Recall: 0.7486626167376915\n",
      "Matrice di confusione:\n",
      "[[988970      1]\n",
      " [  2772   8257]]\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      " Variant I.csv\n",
      "Accuratezza: 0.990196\n",
      "Precisione: 0.9983726606997559\n",
      "Recall: 0.11125215341372745\n",
      "Matrice di confusione:\n",
      "[[988969      2]\n",
      " [  9802   1227]]\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      " Variant II.csv\n",
      "Accuratezza: 0.990184\n",
      "Precisione: 0.9902991107518189\n",
      "Recall: 0.11107081331036359\n",
      "Matrice di confusione:\n",
      "[[988959     12]\n",
      " [  9804   1225]]\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      " Variant III.csv\n",
      "Accuratezza: 0.990075\n",
      "Precisione: 0.9893711248892826\n",
      "Recall: 0.10126926563916591\n",
      "Matrice di confusione:\n",
      "[[988958     12]\n",
      " [  9913   1117]]\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      " Variant IV.csv\n",
      "Accuratezza: 0.990086\n",
      "Precisione: 0.9894736842105263\n",
      "Recall: 0.10226654578422484\n",
      "Matrice di confusione:\n",
      "[[988958     12]\n",
      " [  9902   1128]]\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      " Variant V.csv\n",
      "Accuratezza: 0.990072\n",
      "Precisione: 0.9867491166077739\n",
      "Recall: 0.10126926563916591\n",
      "Matrice di confusione:\n",
      "[[988955     15]\n",
      " [  9913   1117]]\n",
      "\n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fonte in lista_fonti:\n",
    "    print('\\n\\n', fonte)\n",
    "    test(diz_df[fonte], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
