{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import matplotlib_inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "from cycler import cycler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import os\n",
    "\n",
    "# Libreria per importare CSV da Drive\n",
    "# from google.colab import drive\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'png')\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['image.cmap'] = \"viridis\"\n",
    "plt.rcParams['image.interpolation'] = \"none\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['legend.numpoints'] = 1\n",
    "plt.rc('axes', prop_cycle=(\n",
    "    cycler('color', mglearn.plot_helpers.cm_cycle.colors) +\n",
    "    cycler('linestyle', ['-', '-', \"--\", (0, (3, 3)), (0, (1.5, 1.5))])))\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 16)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "__all__ = ['np', 'mglearn', 'display', 'plt', 'pd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelli = ['LogisticRegression', 'KNeighborsClassifier',' DecisionTreeClassifier', 'RandomForestClassifier' ,'SVC', 'GaussianNB', 'LinearDiscriminantAnalysis', 'AdaBoostClassifier' ]\n",
    "modelli = ['RandomForestClassifier']\n",
    "def mod(modello):\n",
    "    if modello == 'LogisticRegression':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        model = LogisticRegression()\n",
    "    \n",
    "    if modello == 'KNeighborsClassifier':\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    if modello == 'DecisionTreeClassifier':\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        model = DecisionTreeClassifier()\n",
    "    if modello == 'RandomForestClassifier':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier()\n",
    "    if modello == 'SVC':\n",
    "        from sklearn.svm import SVC\n",
    "        model = SVC(kernel='linear')\n",
    "    if modello == 'GaussianNB':\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        model = GaussianNB()\n",
    "    if modello == 'LinearDiscriminantAnalysis':\n",
    "        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "        model = LinearDiscriminantAnalysis()\n",
    "    if modello == 'AdaBoostClassifier':\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        model = AdaBoostClassifier()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def ohe(df, list_of_columns):\n",
    "    # Inizializzare OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    \n",
    "    # Manteniamo una copia del DataFrame originale\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # Iterare sulle colonne da codificare\n",
    "    for col in list_of_columns:\n",
    "        # Applicare OneHotEncoder alla colonna specifica\n",
    "        encoded = encoder.fit_transform(df[[col]])\n",
    "\n",
    "        # Creare un DataFrame con le nuove colonne codificate, usando gli stessi indici del DataFrame originale\n",
    "        encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([col]), index=df.index)\n",
    "\n",
    "        # Concatenare le nuove colonne codificate al DataFrame originale\n",
    "        df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "    df_encoded = df_encoded.drop(list_of_columns, axis=1)\n",
    "\n",
    "    # Restituire il DataFrame finale, mantenendo le colonne originali\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith('.csv'):\n",
    "        print(filename)\n",
    "        df_ = pd.read_csv(filename).drop(['device_fraud_count', 'month'], axis=1)\n",
    "        if 'x1' in list(df_.columns):\n",
    "            df_ = df_.drop(['x1', 'x2'], axis=1)\n",
    "        df_['fonte'] = filename\n",
    "        dfs.append(df_)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "\n",
    "lista_fonti = ['Base.csv', 'Variant I.csv', 'Variant II.csv','Variant III.csv','Variant IV.csv','Variant V.csv']\n",
    "diz_df = dict()\n",
    "for l in lista_fonti:\n",
    "    diz_df[l] = df[(df['fonte'] == l)].drop(['fonte'], axis=1).drop_duplicates()\n",
    "\n",
    "diz_df.keys()\n",
    "\n",
    "df = diz_df['Base.csv']\n",
    "df_frodi = df[(df['fraud_bool'] == 1)]\n",
    "n = df[(df['fraud_bool'] == 1)].shape[0]\n",
    "print(n)\n",
    "df_not_frodi = df[(df['fraud_bool'] != 1)]#.head(n*50)\n",
    "\n",
    "df = pd.concat([df_frodi, df_not_frodi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, model):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuratezza: {accuracy}')\n",
    "\n",
    "    # Calcolare la precisione\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f'Precisione: {precision}')\n",
    "\n",
    "    # Calcolare il recall (sensibilità)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    # Calcolare FPR (False Positive Ration)\n",
    "    print(f'FPR: {1 - recall}')\n",
    "\n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Matrice di confusione:\\n{cm}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(df, model):\n",
    "    \n",
    "    df = ohe(df,['employment_status','payment_type','housing_status', 'source', 'device_os'])\n",
    "    y_pred = model.predict(df.drop(['fraud_bool'], axis=1))\n",
    "    y_test = df['fraud_bool']\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuratezza: {accuracy}')\n",
    "\n",
    "    # Calcolare la precisione\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f'Precisione: {precision}')\n",
    "\n",
    "    # Calcolare il recall (sensibilità)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    # Calcolare FPR (False Positive Ration)\n",
    "    print(f'FPR: {1 - recall}')\n",
    "\n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Matrice di confusione:\\n{cm}')\n",
    "\n",
    "    print('\\n__________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849744711889132"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Recall = TN / (TN + FP)\n",
    "#FPR = FP / = 1 - Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (75-25 con rapporto 1 a 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Base.csv\").drop(['device_fraud_count', 'month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11029\n"
     ]
    }
   ],
   "source": [
    "df_frodi = df[(df['fraud_bool'] == 1)]\n",
    "n = df[(df['fraud_bool'] == 1)].shape[0]\n",
    "print(n)\n",
    "df_not_frodi = df[(df['fraud_bool'] != 1)].head(n*50)\n",
    "\n",
    "df = pd.concat([df_frodi, df_not_frodi])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = ohe(df,['employment_status','payment_type','housing_status', 'source', 'device_os'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['fraud_bool'], axis=1), df['fraud_bool'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.9828402787654672\n",
      "Precisione: 0.8063314711359404\n",
      "Recall: 0.15791393143690738\n",
      "FPR: 0.8420860685630926\n",
      "Matrice di confusione:\n",
      "[[137774    104]\n",
      " [  2309    433]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model = train(df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.98061442184611\n",
      "Precisione: 0.7105263157894737\n",
      "Recall: 0.009846827133479213\n",
      "FPR: 0.9901531728665208\n",
      "Matrice di confusione:\n",
      "[[137867     11]\n",
      " [  2715     27]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "model = train(df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.9791281467785521\n",
      "Precisione: 0.3748378728923476\n",
      "Recall: 0.10539752005835157\n",
      "FPR: 0.8946024799416484\n",
      "Matrice di confusione:\n",
      "[[137396    482]\n",
      " [  2453    289]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "model = train(df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.9677997439908974\n",
      "Precisione: 0.2209375\n",
      "Recall: 0.2578409919766594\n",
      "FPR: 0.7421590080233407\n",
      "Matrice di confusione:\n",
      "[[135385   2493]\n",
      " [  2035    707]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model = train(df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "model = train(df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.8922628360119471\n",
      "Precisione: 0.11360239162929746\n",
      "Recall: 0.6652078774617067\n",
      "FPR: 0.33479212253829327\n",
      "Matrice di confusione:\n",
      "[[123646  14232]\n",
      " [   918   1824]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "model = train(df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.9797752808988764\n",
      "Precisione: 0.466796875\n",
      "Recall: 0.2614879649890591\n",
      "FPR: 0.7385120350109409\n",
      "Matrice di confusione:\n",
      "[[137059    819]\n",
      " [  2025    717]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "model = train(df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.9829327264969421\n",
      "Precisione: 0.6734279918864098\n",
      "Recall: 0.24215900802334062\n",
      "FPR: 0.7578409919766593\n",
      "Matrice di confusione:\n",
      "[[137556    322]\n",
      " [  2078    664]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "model = train(df, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
