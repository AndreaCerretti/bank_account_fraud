{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mglearn in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: cycler in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mglearn) (0.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mglearn) (2.1.2)\n",
      "Requirement already satisfied: imageio in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mglearn) (2.36.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mglearn) (2.2.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mglearn) (1.4.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mglearn) (11.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mglearn) (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mglearn) (1.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andrea\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->mglearn) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\andrea\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->mglearn) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mglearn) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mglearn) (3.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mglearn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mglearn) (1.4.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->mglearn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->mglearn) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->mglearn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\andrea\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->mglearn) (1.14.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andrea\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import matplotlib_inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "from cycler import cycler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import *\n",
    "import os\n",
    "\n",
    "# Libreria per importare CSV da Drive\n",
    "# from google.colab import drive\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'png')\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['image.cmap'] = \"viridis\"\n",
    "plt.rcParams['image.interpolation'] = \"none\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['legend.numpoints'] = 1\n",
    "plt.rc('axes', prop_cycle=(\n",
    "    cycler('color', mglearn.plot_helpers.cm_cycle.colors) +\n",
    "    cycler('linestyle', ['-', '-', \"--\", (0, (3, 3)), (0, (1.5, 1.5))])))\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 16)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "__all__ = ['np', 'mglearn', 'display', 'plt', 'pd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def ohe(df, list_of_columns):\n",
    "    # Inizializzare OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    \n",
    "    # Manteniamo una copia del DataFrame originale\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # Iterare sulle colonne da codificare\n",
    "    for col in list_of_columns:\n",
    "        # Applicare OneHotEncoder alla colonna specifica\n",
    "        encoded = encoder.fit_transform(df[[col]])\n",
    "\n",
    "        # Creare un DataFrame con le nuove colonne codificate, usando gli stessi indici del DataFrame originale\n",
    "        encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([col]), index=df.index)\n",
    "\n",
    "        # Concatenare le nuove colonne codificate al DataFrame originale\n",
    "        df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "    df_encoded = df_encoded.drop(list_of_columns, axis=1)\n",
    "\n",
    "    # Restituire il DataFrame finale, mantenendo le colonne originali\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, model):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuratezza: {accuracy}')\n",
    "\n",
    "    # Calcolare la precisione\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f'Precisione: {precision}')\n",
    "\n",
    "    # Calcolare il recall (sensibilità)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    # Calcolare FPR (False Positive Ration)\n",
    "    print(f'FPR: {1 - recall}')\n",
    "\n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Matrice di confusione:\\n{cm}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(df, model):\n",
    "    \n",
    "    df = ohe(df,['employment_status','payment_type','housing_status', 'source', 'device_os'])\n",
    "    y_pred = model.predict(df.drop(['fraud_bool'], axis=1))\n",
    "    y_test = df['fraud_bool']\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuratezza: {accuracy}')\n",
    "\n",
    "    # Calcolare la precisione\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f'Precisione: {precision}')\n",
    "\n",
    "    # Calcolare il recall (sensibilità)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    # Calcolare FPR (False Positive Ration)\n",
    "    print(f'FPR: {1 - recall}')\n",
    "\n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Matrice di confusione:\\n{cm}')\n",
    "\n",
    "    print('\\n__________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849744711889132"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Recall = TN / (TN + FP)\n",
    "#FPR = FP / = 1 - Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (75-25 con rapporto 1 a 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Base.csv\").drop(['device_fraud_count', 'month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11029\n"
     ]
    }
   ],
   "source": [
    "df_frodi = df[(df['fraud_bool'] == 1)]\n",
    "n = df[(df['fraud_bool'] == 1)].shape[0]\n",
    "print(n)\n",
    "df_not_frodi = df[(df['fraud_bool'] != 1)].head(n*50)\n",
    "\n",
    "df = pd.concat([df_frodi, df_not_frodi])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = ohe(df,['employment_status','payment_type','housing_status', 'source', 'device_os'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['fraud_bool'], axis=1), df['fraud_bool'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.9829967287725786\n",
      "Precisione: 0.8268156424581006\n",
      "Recall: 0.16192560175054704\n",
      "FPR: 0.838074398249453\n",
      "Matrice di confusione:\n",
      "[[137785     93]\n",
      " [  2298    444]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model = train(df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11029\n",
      "Cross-validation scores: [0.98  0.98  0.981 0.982 0.982]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Base.csv\").drop(['device_fraud_count', 'month'], axis=1)\n",
    "\n",
    "df_frodi = df[(df['fraud_bool'] == 1)]\n",
    "n = df[(df['fraud_bool'] == 1)].shape[0]\n",
    "print(n)\n",
    "df_not_frodi = df[(df['fraud_bool'] != 1)].head(n*50)\n",
    "\n",
    "df = pd.concat([df_frodi, df_not_frodi])\n",
    "\n",
    "df = ohe(df,['employment_status','payment_type','housing_status', 'source', 'device_os'])\n",
    "\n",
    "k_folds = KFold(n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(model, df.drop('fraud_bool', axis=1), df['fraud_bool'])\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for each feature: [0.021 0.002 0.005 0.004 0.032 0.001 0.002 0.    0.002 0.006 0.013 0.002\n",
      " 0.01  0.006 0.097 0.054 0.103 0.009 0.017 0.034 0.001 0.    0.103 0.132\n",
      " 0.114 0.01  0.001 0.001 0.    0.002 0.    0.03  0.041 0.023 0.006 0.\n",
      " 0.017 0.024 0.058 0.001 0.012 0.    0.    0.119 0.    0.048 0.002 0.039\n",
      " 0.029 0.   ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Calculate Information Gain using mutual_info_classif\n",
    "info_gain = mutual_info_classif(df.drop('fraud_bool', axis=1), df['fraud_bool'])\n",
    "print(\"Information Gain for each feature:\", info_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for each feature: [0.021 0.002 0.005 0.004 0.032 0.001 0.002 0.    0.002 0.006 0.013 0.002\n",
      " 0.01  0.006 0.097 0.054 0.103 0.009 0.017 0.034 0.001 0.    0.103 0.132\n",
      " 0.114 0.01  0.001 0.001 0.    0.002 0.    0.03  0.041 0.023 0.006 0.\n",
      " 0.017 0.024 0.058 0.001 0.012 0.    0.    0.119 0.    0.048 0.002 0.039\n",
      " 0.029 0.   ]\n",
      "Index(['income', 'name_email_similarity', 'prev_address_months_count',\n",
      "       'current_address_months_count', 'customer_age', 'days_since_request',\n",
      "       'intended_balcon_amount', 'zip_count_4w', 'velocity_6h', 'velocity_24h',\n",
      "       'velocity_4w', 'bank_branch_count_8w',\n",
      "       'date_of_birth_distinct_emails_4w', 'credit_risk_score',\n",
      "       'email_is_free', 'phone_home_valid', 'phone_mobile_valid',\n",
      "       'bank_months_count', 'has_other_cards', 'proposed_credit_limit',\n",
      "       'foreign_request', 'session_length_in_minutes', 'keep_alive_session',\n",
      "       'device_distinct_emails_8w', 'employment_status_CA',\n",
      "       'employment_status_CB', 'employment_status_CC', 'employment_status_CD',\n",
      "       'employment_status_CE', 'employment_status_CF', 'employment_status_CG',\n",
      "       'payment_type_AA', 'payment_type_AB', 'payment_type_AC',\n",
      "       'payment_type_AD', 'payment_type_AE', 'housing_status_BA',\n",
      "       'housing_status_BB', 'housing_status_BC', 'housing_status_BD',\n",
      "       'housing_status_BE', 'housing_status_BF', 'housing_status_BG',\n",
      "       'source_INTERNET', 'source_TELEAPP', 'device_os_linux',\n",
      "       'device_os_macintosh', 'device_os_other', 'device_os_windows',\n",
      "       'device_os_x11'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Information Gain for each feature:\", info_gain)\n",
    "print(df.drop('fraud_bool', axis=1).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le feature con più information gain sono:\n",
    "- device_distinct_emails_8w (0.132)\n",
    "- source_INTERNET (0.119)\n",
    "- employment_status_CA (0.114)\n",
    "- phone_mobile_valid (0.103)\n",
    "- keep_alive_session (0.103)\n",
    "- email_is_free (0.097)\n",
    "- housing_status_BC (0.058)\n",
    "- phone_home_valid (0.054)\n",
    "- device_os_linux (0.048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punteggi totali:\n",
    "\n",
    "0.    : 'employment_status_CE'\n",
    "0.    : 'employment_status_CG'      \n",
    "0.    : 'housing_status_BF'\n",
    "0.    : 'housing_status_BG'   \n",
    "0.    : 'session_length_in_minutes'\n",
    "0.    : 'source_TELEAPP'\n",
    "0.    : 'zip_count_4w'\n",
    "0.: 'device_os_x11'\n",
    "0.: 'payment_type_AE'\n",
    "0.001 : 'days_since_request'    \n",
    "0.001 : 'employment_status_CC'\n",
    "0.001 : 'employment_status_CD'\n",
    "0.001 : 'foreign_request'\n",
    "0.001 : 'housing_status_BD'   \n",
    "0.002 : 'device_os_macintosh'\n",
    "0.002 : 'employment_status_CF'\n",
    "0.002 : 'intended_balcon_amount'\n",
    "0.002 : 'name_email_similarity'\n",
    "0.002 : 'velocity_6h'\n",
    "0.002: 'bank_branch_count_8w'   \n",
    "0.004 : 'current_address_months_count'\n",
    "0.005 : 'prev_address_months_count'\n",
    "0.006 : 'credit_risk_score'  \n",
    "0.006 : 'payment_type_AD'\n",
    "0.006 : 'velocity_24h'    \n",
    "0.009 : 'bank_months_count'\n",
    "0.01  : 'date_of_birth_distinct_emails_4w'\n",
    "0.01  : 'employment_status_CB'\n",
    "0.012 : 'housing_status_BE'\n",
    "0.013 : 'velocity_4w'\n",
    "0.017 : 'has_other_cards'\n",
    "0.017 : 'housing_status_BA'    \n",
    "0.021 : 'income'\n",
    "0.023 : 'payment_type_AC'      \n",
    "0.024 : 'housing_status_BB'\n",
    "0.029 : 'device_os_windows'   \n",
    "0.03  : 'payment_type_AA'\n",
    "0.032 : 'customer_age'\n",
    "0.034 : 'proposed_credit_limit'\n",
    "0.039: 'device_os_other'\n",
    "0.041 : 'payment_type_AB'\n",
    "0.048 : 'device_os_linux'      \n",
    "0.054 : 'phone_home_valid'\n",
    "0.058 : 'housing_status_BC'\n",
    "0.097 : 'email_is_free'\n",
    "0.103 : 'keep_alive_session'    \n",
    "0.103 : 'phone_mobile_valid'  \n",
    "0.114 : 'employment_status_CA'\n",
    "0.119 : 'source_INTERNET'\n",
    "0.132: 'device_distinct_emails_8w'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
